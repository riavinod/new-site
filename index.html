---
layout: none
date:   ""
---
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Ria Vinod</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
    {% include sidebar.html %}
<section>

<h2>
<a id="about-me" class="anchor" href="#about-me" aria-hidden="true"><span class="octicon octicon-link"></span></a>About me</h2>

<p>I'm currently a 2nd Year PhD student at Brown University being supervised by <a href="http://www.lorincrawford.com">Lorin Crawford</a>. I work on protein-design problems and learning data-efficient representations from multimodal distributions.</p>

<p>Before that, I studied Electrical Engineering and Computer Science at UC Berkeley and graduated in 2021. </p>

<p>I've spent summers at IBM Research, Salesforce and Optum, working on different research and data engineering problems. </p>

<p>I'm still learning a lot about math and proteins, so I'm trying to make notes and collect useful links as I go along. You can find notes <a href="/posts/proteins">here</a> and interesting reads <a href="/posts/useful_reads">here</a>. Some of the workflows that I've created as I've needed them can be found on my <a href="https://www.github.com/riavinod">github</a></p>

<p>I also spend time co-organizing a <a href="https://www.ml4proteinengineering.com">Machine Learning x Proteins seminar series</a> and co-run after-school computational science workshops at Providence public schools with some of my wonderful peers.</p>

<p>As a new graduate student, I thought <a href="/posts/new-graduate-student">these resources</a> were super useful (some Boston-area specific ones too!).</p>


<!-- <p>I have a <a href="/posts">blog</a> where I write about topics of interest to me: as of the time I write this, there are posts about <a href="https://danielfilan.com/2022/03/10/prob_smart_londoner_dies_of_russian_nuke.html">forecasting</a>, <a href="https://danielfilan.com/2022/02/11/nice_representation_laplacian.html">math</a>, and <a href="https://danielfilan.com/2021/11/21/meta_puzzle.html">puzzles</a>.</p>

<p>I also have a <a href="https://axrp.net">podcast</a> about this field of research. It's called <a href="https://axrp.net">AXRP</a>, which is short for the AI X-risk Research Podcast. You can listen to episodes on <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9heHJwb2RjYXN0LmxpYnN5bi5jb20vcnNz">Google podcasts</a>, or by searching "AXRP" in your favourite podcast app. Alteratively, you can read transcripts <a href="https://axrp.net">here</a>.</p>

<p>I'm interested in <a href="https://www.effectivealtruism.org/">effective altruism</a>, how we can use our limited resources to do the most good in the world. I also sometimes <a href="/bets">bet on things</a>, for reasons described by <a href="http://econlog.econlib.org/archives/2012/05/the_bettors_oat.html">Bryan Caplan</a> and <a href="http://econlog.econlib.org/archives/2014/07/kant_on_betting.html">Immanuel Kant</a>.</p>

<p>I did my undergrad at the Australian National University, studying the theory of reinforcement learning, mathematics, and theoretical physics. I did my honours year (similar to a research master's degree lasting one year) under <a href="http://www.hutter1.net/">Marcus Hutter</a>; you can read my thesis "Resource-bounded Complexity-based Priors for Agents" <a href="/pdfs/thesis.pdf">here</a>.</p> -->

<h3>Research Projects</h3>

<ul>

<li><strong>Representation Learning for Molecular Property Prediction.</strong> <a href="https://arxiv.org/abs/2012.03460">arxiv</a><br>
With Pin-Yu Chen and Payel Das.<br>
Introduces the dictionary learning to utilize learned representations from pretrained deep models for functional and structural molecular property prediction. Presented at WiML, LMRL @ NeurIPS 2020.


<li><strong>Data-Efficient Representation Learning as an Alternative to Pretraining.</strong> <!-- <a href="https://arxiv.org/abs/2012.03460">arxiv</a> --> <br>
With Pin-Yu Chen and Payel Das.<br>
Introduces a representation learning framework in which deep language models are reprogrammed for alternate tasks that can perform well in low-training data settings.

  <li><strong>Diffusion Modelling for Sequence-Structure.</strong> <!-- <a href="https://arxiv.org/abs/1807.05037">arxiv</a> --> <br>
With Lorin Crawford, Kevin Yang.<br>
Investigating sequence-structure distributions through diffusion-based generative modelling for various downstream protein prediction tasks.



</ul>

    </div>
    <script src="javascripts/scale.fix.js"></script>
</section>
  </body>
</html>
